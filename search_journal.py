import os
import sys
import re
import pickle
import argparse
import subprocess
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import concurrent.futures
import io

# OCR Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸
try:
    import fitz  # PyMuPDF
    from PIL import Image
    import pytesseract
    import cv2
    import numpy as np
    OCR_AVAILABLE = True
except ImportError as e:
    print(f"ÐŸÑ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ðµ: ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¸Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ OCR Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸: {e}")
    print("Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸: pip install PyMuPDF Pillow pytesseract opencv-python numpy")
    OCR_AVAILABLE = False


class JournalSearchEngine:
    def __init__(self, pdfs_folder: Path = Path('local'), cache_folder: Path = Path('ocr_cache')):
        self.pdfs_folder = pdfs_folder
        self.cache_folder = cache_folder
        self.cache_folder.mkdir(exist_ok=True)

        if not OCR_AVAILABLE:
            raise ImportError("OCR Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÐ¸ Ð½Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ñ‹. Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸")

        self.setup_tesseract()

        self.ocr_languages = "rus+eng"

        self.dpi = 200
        self.max_workers = 2 
        
    def setup_tesseract(self):
        """ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿ÑƒÑ‚Ð¸ Ðº Tesseract OCR"""
        self.tesseract_available = False

        possible_paths = [
            r"C:\Program Files\Tesseract-OCR\tesseract.exe",
            r"C:\Program Files (x86)\Tesseract-OCR\tesseract.exe",
            "/usr/bin/tesseract",
            "/usr/local/bin/tesseract",
        ]
        
        try:
            if sys.platform == "win32":
                result = subprocess.run(["where", "tesseract"], 
                                      capture_output=True, text=True, shell=True)
            else:
                result = subprocess.run(["which", "tesseract"], 
                                      capture_output=True, text=True)
            
            if result.returncode == 0:
                tesseract_path = result.stdout.strip().split('\n')[0]
                possible_paths.insert(0, tesseract_path)
        except:
            pass

        for tesseract_path in possible_paths:
            if os.path.exists(tesseract_path):
                try:
                    pytesseract.pytesseract.tesseract_cmd = tesseract_path
                    print(f"âœ“ ÐÐ°Ð¹Ð´ÐµÐ½ Tesseract: {tesseract_path}")

                    version = pytesseract.get_tesseract_version()
                    print(f"âœ“ Ð’ÐµÑ€ÑÐ¸Ñ Tesseract: {version}")
                    
                    self.tesseract_available = True
                    return
                except Exception as e:
                    print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐµ {tesseract_path}: {e}")
                    continue
        
        if not self.tesseract_available:
            print("\n" + "="*60)
            print("TESSERACT OCR ÐÐ• ÐÐÐ™Ð”Ð•Ð!")
            print("="*60)
            print("Ð£ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚Ðµ Tesseract OCR Ñ Ð¾Ñ„Ð¸Ñ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ ÑÐ°Ð¹Ñ‚Ð°")
            print("https://github.com/UB-Mannheim/tesseract/wiki")
            print("="*60)
    
    def load_pdf_files(self) -> List[Path]:

        if not self.pdfs_folder.exists():
            print(f"âœ— ÐŸÐ°Ð¿ÐºÐ° {self.pdfs_folder} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°.")
            return []

        pdf_files = set()

        for ext in ['.pdf', '.PDF', '.Pdf', '.pDF']:
            for file_path in self.pdfs_folder.glob(f'*{ext}'):
                pdf_files.add(file_path)

        unique_files = sorted(pdf_files)
        
        if unique_files:
            print(f"âœ“ ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(unique_files)} PDF Ñ„Ð°Ð¹Ð»Ð¾Ð²:")
            for file in unique_files:
                print(f"  - {file.name}")
            return unique_files
        else:
            print(f"âœ— PDF Ñ„Ð°Ð¹Ð»Ñ‹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ñ‹ Ð² Ð¿Ð°Ð¿ÐºÐµ {self.pdfs_folder}")
            return []
        
    def preprocess_image(self, image: Image.Image) -> Image.Image:
        try:
            img_array = np.array(image)
            
            if len(img_array.shape) == 3:
                gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
            else:
                gray = img_array
            
            gray = cv2.convertScaleAbs(gray, alpha=1.5, beta=10)
            
            gray = cv2.medianBlur(gray, 1)
            
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(binary, -1, kernel)
            
            return Image.fromarray(sharpened)
            
        except Exception as e:
            print(f"âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ: {e}")
            return image
    
    def pdf_to_images(self, pdf_path: Path) -> List[Image.Image]:
        images = []
        
        try:
            doc = fitz.open(pdf_path)
            print(f"  ÐžÑ‚ÐºÑ€Ñ‹Ñ‚ PDF: {pdf_path.name}, ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†: {len(doc)}")
            
            for page_num in range(len(doc)):
                page = doc[page_num]

                zoom = self.dpi / 72 
                mat = fitz.Matrix(zoom, zoom)
             
                pix = page.get_pixmap(matrix=mat, alpha=False)
                
                img_data = pix.tobytes("png")
                image = Image.open(io.BytesIO(img_data))
                images.append(image)
               
                if (page_num + 1) % 10 == 0:
                    print(f"    ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¾ {page_num + 1} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†...")
            
            doc.close()
            
        except Exception as e:
            print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð°Ñ†Ð¸Ð¸ {pdf_path.name}: {e}")
        
        return images
    
    def extract_text_from_pdf(self, pdf_path: Path, use_cache: bool = True) -> Dict[int, str]:
        if not self.tesseract_available:
            print("âœ— Tesseract Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½")
            return {}
    
        cache_file = self.cache_folder / f"{pdf_path.stem}_cache.pkl"
       
        if use_cache and cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    print(f"âœ“ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¸Ð· ÐºÑÑˆÐ°: {pdf_path.name}")
                    return pickle.load(f)
            except Exception as e:
                print(f"âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ ÐºÑÑˆÐ° {pdf_path.name}: {e}")
        
        print(f"ðŸ” ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»: {pdf_path.name}")
        page_texts = {}
        
        try:
            images = self.pdf_to_images(pdf_path)
            
            if not images:
                print(f"âœ— ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ {pdf_path.name}")
                return {}
            
            print(f"  Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð¸Ð· {len(images)} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†...")
            
            for page_num, image in enumerate(images, 1):
                processed_image = self.preprocess_image(image)
                
                text = pytesseract.image_to_string(
                    processed_image,
                    lang=self.ocr_languages,
                    config='--psm 3 --oem 3 -c preserve_interword_spaces=1'
                )
                
                page_texts[page_num] = text
                
                if page_num % 5 == 0:
                    print(f"    Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾ {page_num}/{len(images)} ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†...")
            
            print(f"âœ“ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½ Ñ„Ð°Ð¹Ð»: {pdf_path.name}")
            
        except Exception as e:
            print(f"âœ— ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ {pdf_path.name}: {e}")
            return {}
        
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(page_texts, f)
            print(f"ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ Ð² ÐºÑÑˆ: {pdf_path.name}")
        except Exception as e:
            print(f"âš  ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÐºÑÑˆÐ°: {e}")
        
        return page_texts
    
    def search_in_pdf(self, pdf_path: Path, search_words: List[str], 
                      case_sensitive: bool = False, 
                      match_whole_word: bool = True) -> Dict:
        results = {
            'filename': pdf_path.name,
            'filepath': str(pdf_path),
            'found_words': [],
            'total_matches': 0,
            'pages_with_matches': [],
            'details': []
        }
        
        page_texts = self.extract_text_from_pdf(pdf_path)
        
        if not page_texts:
            return results
        
        search_terms = search_words if case_sensitive else [w.lower() for w in search_words]
        
        for page_num, text in page_texts.items():
            search_text = text if case_sensitive else text.lower()
            
            page_matches = []
            
            for i, term in enumerate(search_terms):
                if match_whole_word:
                    pattern = r'\b' + re.escape(term) + r'\b'
                    matches = list(re.finditer(pattern, search_text, re.IGNORECASE))
                else:
                    pattern = re.escape(term)
                    matches = list(re.finditer(pattern, search_text, re.IGNORECASE))
                
                if matches:
                    first_match = matches[0]
                    start_pos = max(0, first_match.start() - 50)
                    end_pos = min(len(text), first_match.end() + 50)
                    context = text[start_pos:end_pos].replace('\n', ' ').strip()
                    
                    if len(context) > 150:
                        context = context[:150] + "..."
                    
                    page_matches.append({
                        'word': search_words[i], 
                        'count': len(matches),
                        'context': context
                    })
            
            if page_matches:
                results['pages_with_matches'].append(page_num)
                results['total_matches'] += sum(m['count'] for m in page_matches)
                results['details'].append({
                    'page': page_num,
                    'matches': page_matches
                })
        
        for detail in results['details']:
            for match in detail['matches']:
                if match['word'] not in results['found_words']:
                    results['found_words'].append(match['word'])
        
        return results
    
    def search_across_all_pdfs(self, search_words: List[str], 
                               max_workers: int = None,
                               **search_kwargs) -> List[Dict]:
        pdf_files = self.load_pdf_files()
        
        if not pdf_files:
            return []
        
        if max_workers is None:
            max_workers = self.max_workers
        
        print(f"\nðŸ”Ž ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ {len(pdf_files)} Ñ„Ð°Ð¹Ð»Ð°Ð¼...")
        print(f"ðŸ“ Ð˜Ñ‰ÐµÐ¼ ÑÐ»Ð¾Ð²Ð°: {', '.join(search_words)}")
        print("â³ Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ðµ Ð²Ñ€ÐµÐ¼Ñ...\n")
        
        results = []
        
        for pdf in pdf_files:
            try:
                result = self.search_in_pdf(pdf, search_words, **search_kwargs)
                if result['total_matches'] > 0:
                    results.append(result)
                    print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð² {pdf.name}: {result['total_matches']} ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹")
                else:
                    print(f"âŒ ÐÐµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² {pdf.name}")
            except Exception as e:
                print(f"âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ {pdf.name}: {e}")
        
        results.sort(key=lambda x: x['total_matches'], reverse=True)
        
        return results
    
    def print_results(self, results: List[Dict], search_words: List[str]):
        if not results:
            print("\n" + "="*60)
            print("âŒ Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾")
            print("="*60)
            return
        
        print("\n" + "="*60)
        print(f"ðŸŽ‰ Ð Ð•Ð—Ð£Ð›Ð¬Ð¢ÐÐ¢Ð« ÐŸÐžÐ˜Ð¡ÐšÐ ({len(results)} Ñ„Ð°Ð¹Ð»Ð¾Ð²)")
        print("="*60)
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. ðŸ“„ Ð¤Ð°Ð¹Ð»: {result['filename']}")
            print(f"   ðŸ”¢ Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {result['total_matches']}")
            print(f"   ðŸ“– Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹: {', '.join(map(str, result['pages_with_matches']))}")
            
            if result['found_words']:
                print(f"   ðŸ·ï¸  ÐÐ°Ð¹Ð´ÐµÐ½Ð½Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°: {', '.join(result['found_words'])}")
            
            if result['details']:
                print("   ðŸ“ ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:")
                for detail in result['details'][:2]: 
                    print(f"   - Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {detail['page']}:")
                    for match in detail['matches'][:2]: 
                        print(f"     '{match['word']}': {match['context']}")
        
        print("\n" + "="*60)
        print(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð² {len(results)} Ñ„Ð°Ð¹Ð»Ð°Ñ…")
        print("="*60)


def main():
    parser = argparse.ArgumentParser(description='ÐŸÐ¾Ð¸ÑÐº Ð¿Ð¾ Ð¾Ñ‚ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼ PDF Ð¶ÑƒÑ€Ð½Ð°Ð»Ð°Ð¼')
    parser.add_argument('words', nargs='+', help='Ð¡Ð»Ð¾Ð²Ð° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°')
    parser.add_argument('--folder', default='local', help='ÐŸÐ°Ð¿ÐºÐ° Ñ PDF Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸')
    parser.add_argument('--cache', default='ocr_cache', help='ÐŸÐ°Ð¿ÐºÐ° Ð´Ð»Ñ ÐºÑÑˆÐ°')
    parser.add_argument('--no-cache', action='store_true', help='ÐÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ ÐºÑÑˆ')
    parser.add_argument('--case-sensitive', action='store_true', help='Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€')
    parser.add_argument('--partial', action='store_true', help='Ð˜ÑÐºÐ°Ñ‚ÑŒ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ')
    parser.add_argument('--threads', type=int, default=1, help='ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ¾Ð²')
    
    args = parser.parse_args()
    
    try:
        engine = JournalSearchEngine(
            pdfs_folder=Path(args.folder),
            cache_folder=Path(args.cache)
        )
        
        if not args.no_cache:
            print("ðŸ’¾ Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ ÐºÑÑˆ")
        
        results = engine.search_across_all_pdfs(
            search_words=args.words,
            max_workers=args.threads,
            case_sensitive=args.case_sensitive,
            match_whole_word=not args.partial
        )
        
        engine.print_results(results, args.words)
        
        if results:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"search_results_{timestamp}.txt"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(f"ÐŸÐ¾Ð¸ÑÐº: {', '.join(args.words)}\n")
                f.write(f"Ð’Ñ€ÐµÐ¼Ñ: {datetime.now()}\n")
                f.write(f"ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ñ„Ð°Ð¹Ð»Ð¾Ð²: {len(results)}\n\n")
                
                for result in results:
                    f.write(f"{'='*50}\n")
                    f.write(f"Ð¤Ð°Ð¹Ð»: {result['filename']}\n")
                    f.write(f"Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {result['total_matches']}\n")
                    f.write(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹: {', '.join(map(str, result['pages_with_matches']))}\n")
                    
                    if result['found_words']:
                        f.write(f"Ð¡Ð»Ð¾Ð²Ð°: {', '.join(result['found_words'])}\n")
                    
                    f.write("\n")
            
            print(f"\nðŸ’¾ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² {output_file}")
        
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")
        return 1
    
    return 0


def interactive_search():
    print("="*60)
    print("ðŸ” ÐŸÐžÐ˜Ð¡Ðš ÐŸÐž Ð–Ð£Ð ÐÐÐ›ÐÐœ (OCR)")
    print("="*60)
    
    try:
        engine = JournalSearchEngine()
        
        while True:
            print("\nÐ’Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° (Ñ‡ÐµÑ€ÐµÐ· Ð¿Ñ€Ð¾Ð±ÐµÐ») Ð¸Ð»Ð¸ 'q' Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð°:")
            user_input = input("> ").strip()
            
            if user_input.lower() in ['q', 'quit', 'exit', 'Ð²Ñ‹Ñ…Ð¾Ð´']:
                print("ðŸ‘‹ Ð’Ñ‹Ñ…Ð¾Ð´ Ð¸Ð· Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ñ‹")
                break
            
            if not user_input:
                continue
            
            search_words = [w.strip() for w in user_input.split() if w.strip()]
            
            print("\nÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¿Ð¾Ð¸ÑÐºÐ°:")
            print("1. Ð£Ñ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ‚ÑŒ Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€")
            print("2. Ð˜ÑÐºÐ°Ñ‚ÑŒ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ñ")
            print("3. ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð¿Ð¾Ð¸ÑÐº (Ñ†ÐµÐ»Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°, Ð±ÐµÐ· ÑƒÑ‡ÐµÑ‚Ð° Ñ€ÐµÐ³Ð¸ÑÑ‚Ñ€Ð°)")
            
            choice = input("Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚ (1-3, Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 3): ").strip()
            
            case_sensitive = (choice == '1')
            match_whole_word = (choice != '2')
            
            print(f"\nðŸ”Ž ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð¿Ð¾Ð¸ÑÐº: {', '.join(search_words)}...")
            
            results = engine.search_across_all_pdfs(
                search_words=search_words,
                case_sensitive=case_sensitive,
                match_whole_word=match_whole_word
            )
            
            engine.print_results(results, search_words)
            
            if results:
                save = input("\nðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² Ñ„Ð°Ð¹Ð»? (y/n): ").lower()
                if save == 'y':
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    search_str = '_'.join(search_words[:3])  # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ñ‹Ðµ 3 ÑÐ»Ð¾Ð²Ð°
                    output_file = f"search_{search_str}_{timestamp}.txt"
                    
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(f"ÐŸÐ¾Ð¸ÑÐº: {', '.join(search_words)}\n")
                        f.write(f"Ð’Ñ€ÐµÐ¼Ñ: {datetime.now()}\n\n")
                        
                        for result in results:
                            f.write(f"{'='*50}\n")
                            f.write(f"Ð¤Ð°Ð¹Ð»: {result['filename']}\n")
                            f.write(f"Ð¡Ð¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹: {result['total_matches']}\n")
                            f.write(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹: {', '.join(map(str, result['pages_with_matches']))}\n\n")
                            
                            for detail in result['details']:
                                f.write(f"Ð¡Ñ‚Ñ€Ð°Ð½Ð¸Ñ†Ð° {detail['page']}:\n")
                                for match in detail['matches']:
                                    f.write(f"  - {match['word']}: {match['context']}\n")
                                f.write("\n")
                    
                    print(f"âœ… Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð² {output_file}")
    
    except KeyboardInterrupt:
        print("\n\nâš  ÐŸÑ€Ð¾Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¿Ñ€ÐµÑ€Ð²Ð°Ð½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")
    except Exception as e:
        print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ°: {e}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        sys.exit(main())
    else:
        interactive_search()